{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 gpt-3.5-turbo model의 chat endpoint function (2023년 6월 openai gpt-3.5-turbo update)\n",
    "\n",
    "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
    "    messages = [{'role': 'user',\n",
    "                 'content' : prompt}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature= 0,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8pcEmiqnWdhSKeFLBFUXZ3LbKGweR at 0x1098aefc0> JSON: {\n",
       "  \"id\": \"chatcmpl-8pcEmiqnWdhSKeFLBFUXZ3LbKGweR\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1707312404,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The capital of France is Paris.\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"completion_tokens\": 7,\n",
       "    \"total_tokens\": 20\n",
       "  },\n",
       "  \"system_fingerprint\": null\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role' : 'user',\n",
    "                 'content' : 'What is the capital of France'}],\n",
    "    temperature = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8pcEmpGmfs00hQqp7ggKBrwDDRaWu at 0x1098adb20> JSON: {\n",
       "  \"id\": \"chatcmpl-8pcEmpGmfs00hQqp7ggKBrwDDRaWu\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1707312404,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The capital of France is Paris.\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"completion_tokens\": 7,\n",
       "    \"total_tokens\": 20\n",
       "  },\n",
       "  \"system_fingerprint\": null\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [{'role' : 'user',\n",
    "                 'content' : 'What is the capital of France'}],\n",
    "    temperature = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The reversed letters of \"lollipop\" are \"pillipol\".'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion('Take the letters in lollipop and reverse them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p-o-p-i-l-l-o-l'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion('Take the letters in l-o-l-l-i-p-o-p and reverse them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function (chat format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model='gpt-3.5-turbo',\n",
    "                                 temperature = 0,\n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature,\n",
    "        max_tokens = max_tokens\n",
    "    )\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carro, so bright and orange,\n",
      "With a smile on its face, it's never a bore.\n",
      "It rolls down the road, full of joy and cheer,\n",
      "Spreading happiness far and near.\n",
      "\n",
      "Its wheels go round and round, with a hop and a skip,\n",
      "As it carries its passengers on a happy trip.\n",
      "With a crunch and a munch, it chomps on the road,\n",
      "Bringing smiles to all, wherever it goes.\n",
      "\n",
      "The carro is jolly, it's always a delight,\n",
      "With a trunk full of laughter, shining so bright.\n",
      "So let's all be like the happy carro,\n",
      "Spreading joy and happiness, wherever we go!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"You are an assistant who responds in the style of EDr Seuss.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a very short poem aobut a happy carro\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Joyful and delicious, a veggie to gorge.\n",
      "With a smile so wide, from tip to tail,\n",
      "A perfect little veggie, that will never fail.\n",
      "\n",
      "In the garden it grew, with love and care,\n",
      "As the sun beamed down, it's warmth so fair.\n",
      "The soil was rich, so deep and sound,\n",
      "Nurturing the carrot, beneath the ground.\n",
      "\n",
      "It grew with laughter, and giggles too,\n",
      "With friends like peas and lettuce, a happy crew.\n",
      "Feeding the world, with vitamins and glee,\n",
      "A healthy, happy carrot, for you and me.\n",
      "\n",
      "So let us celebrate, this cheerful root,\n",
      "Crunch it in a salad, or juice it for fruit.\n",
      "For the happy carrot, brings delight galore,\n",
      "A vegetable superstar, that we adore!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"You are an assistant who responds in the style of EDr Seuss.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a very short poem aobut a happy carrot\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Charlie who lived in a vibrant vegetable garden.\n"
     ]
    }
   ],
   "source": [
    "## length 조절\n",
    "\n",
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"All your responses must be one sentence long.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a story about a happy carrot\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Charlie who lived in a vibrant vegetable garden.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"All your responses must be one sentence long.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a story about a happy carrot\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0.5)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Charlie who spent his days basking in the warm sunshine and growing into the best carrot he could be.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"All your responses must be one sentence long.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a story about a happy carrot\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## token 산정\n",
    "\n",
    "def get_completion_and_token_count(messages,\n",
    "                                   model = 'gpt-3.5-turbo',\n",
    "                                   temperature=0,\n",
    "                                   max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature,\n",
    "        max_tokens= max_tokens\n",
    "        \n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message['content']\n",
    "    \n",
    "    token_dict = {\n",
    "        'prompt_tokens' : response['usage']['prompt_tokens'],\n",
    "        'completion_tokens' : response['usage']['completion_tokens'],\n",
    "        'total_tokens' : response['usage']['total_tokens'],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Grown in the garden, a joyful forage.\n",
      "With a leafy green top, reaching for the sky,\n",
      "This little veggie brings a smile to the eye.\n",
      "\n",
      "From the earth it sprouts, with a cheerful face,\n",
      "Filled with vitamins, a healthy embrace.\n",
      "Crunchy and sweet, a delightful treat,\n",
      "The happy carrot is a veggie so neat.\n",
      "\n",
      "So let's celebrate this veggie so grand,\n",
      "With a joyful dance and a clap of the hand.\n",
      "For the happy carrot, oh what a delight,\n",
      "Bringing happiness with every bite!\n",
      "{'prompt_tokens': 35, 'completion_tokens': 123, 'total_tokens': 158}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system',\n",
    "     'content' : \"\"\"You are an assistant who respons in the style of Dr Seuss.\"\"\"},\n",
    "    {'role' : 'user',\n",
    "     'content' : \"\"\"write me a very short poem about a happy carrot\"\"\"},\n",
    "]\n",
    "\n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    일반적으로 LLM을 사용하여 작업할 때는 프롬프트의 개행 문자('\\')가 모델 성능에 영향을 미칠 수 있는지 여부를 고려할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
