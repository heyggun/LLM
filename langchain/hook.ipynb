{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goyoai_ai_server.hub.model.chat import (\n",
    "    OpenAIChatModelNamesEnum,\n",
    "    get_chat_model,\n",
    ")\n",
    "\n",
    "chat_model = get_chat_model(OpenAIChatModelNamesEnum.GPT4O_MINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BrdAJYosGrZGTH8R1vp2t9Xlkby88', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ee0a2d8-44e5-4384-859b-8f0306ecc8d2-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goyoai_ai_server.services.intern.tools.web_search.perplexity.tool import PerplexityWebSearchTool\n",
    "\n",
    "web_search_tool = PerplexityWebSearchTool()\n",
    "tools = [web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = chat_model.bind_tools(tools)\n",
    "\n",
    "def call_llm_node(state: AgentState) -> AgentState:\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    print(\"ğŸ§  LLM ì‘ë‹µ:\", response.content)\n",
    "    print(\"ğŸ§© Tool Calls:\", getattr(response, \"tool_calls\", None))  # ğŸ‘ˆ ì´ê²Œ ìˆì–´ì•¼ tool ì‹¤í–‰ë¨\n",
    "    return {\"messages\": state[\"messages\"] + [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def tool_executor(state: AgentState) -> AgentState:\n",
    "    last_message = state['messages'][-1]\n",
    "    if hasattr(last_message, \"tool_calls\"):\n",
    "        new_messages = state[\"messages\"]\n",
    "        for call in last_message.tool_calls:\n",
    "            tool_name = call[\"name\"]\n",
    "            args = call[\"args\"]\n",
    "            tool = next(t for t in tools if t.name == tool_name)\n",
    "            result, _ = tool._run(**args)\n",
    "            tool_msg = ToolMessage(content=result, tool_call_id=call[\"id\"])\n",
    "            new_messages.append(tool_msg)\n",
    "        return {\"messages\" : new_messages}\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph = StateGraph(state_schema=AgentState)\n",
    "\n",
    "graph.add_node(\"call_llm\", RunnableLambda(call_llm_node))\n",
    "graph.add_node(\"call_tool\", tool_executor)\n",
    "\n",
    "graph.set_entry_point(\"call_llm\")\n",
    "\n",
    "def should_use_tool(state: AgentState) -> str:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "        return \"call_tool\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "graph.add_conditional_edges(\"call_llm\", should_use_tool)\n",
    "graph.add_edge(\"call_tool\", \"call_llm\")\n",
    "graph.set_finish_point(\"call_llm\")\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLM ì‘ë‹µ: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ğŸ§  LLM ì‘ë‹µ: \n",
      "ğŸ§© Tool Calls: [{'name': 'web_search', 'args': {'query': 'ì˜¤ëŠ˜ ë‚ ì”¨'}, 'id': 'call_rZkhVW0DrvIffANrKDLjza67', 'type': 'tool_call'}]\n",
      "ğŸ§  LLM ì‘ë‹µ: ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì§€ë§Œ, ê¸°ìƒì²­ì˜ [ë‚ ì”¨ëˆ„ë¦¬](https://www.weather.go.kr/w/weather/now.do) ì›¹ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•˜ë©´ í˜„ì¬ ìœ„ì¹˜ì˜ ìµœì‹  ë‚ ì”¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ë‚ ì”¨ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°í˜¸ë¡œ ì„¤ëª…ë©ë‹ˆë‹¤:\n",
      "- ë§‘ìŒ\n",
      "- êµ¬ë¦„ì¡°ê¸ˆ\n",
      "- êµ¬ë¦„ë§ìŒ\n",
      "- íë¦¼\n",
      "- ì†Œë‚˜ê¸°\n",
      "- ë¹„\n",
      "- ëˆˆ\n",
      "- ë¹„ ë˜ëŠ” ëˆˆ\n",
      "\n",
      "ì›í•˜ëŠ” ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ì‹œë ¤ë©´ ìœ„ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì§€ë§Œ, ê¸°ìƒì²­ì˜ [ë‚ ì”¨ëˆ„ë¦¬](https://www.weather.go.kr/w/weather/now.do) ì›¹ì‚¬ì´íŠ¸ë¥¼ ë°©ë¬¸í•˜ë©´ í˜„ì¬ ìœ„ì¹˜ì˜ ìµœì‹  ë‚ ì”¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ë‚ ì”¨ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°í˜¸ë¡œ ì„¤ëª…ë©ë‹ˆë‹¤:\n",
      "- ë§‘ìŒ\n",
      "- êµ¬ë¦„ì¡°ê¸ˆ\n",
      "- êµ¬ë¦„ë§ìŒ\n",
      "- íë¦¼\n",
      "- ì†Œë‚˜ê¸°\n",
      "- ë¹„\n",
      "- ëˆˆ\n",
      "- ë¹„ ë˜ëŠ” ëˆˆ\n",
      "\n",
      "ì›í•˜ëŠ” ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ì‹œë ¤ë©´ ìœ„ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§  LLM ì‘ë‹µ: ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§  LLM ì‘ë‹µ: ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ì–´ë–¤ ì •ë³´ë¥¼ ì°¾ê³  ê³„ì‹ ê°€ìš”?\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ì–´ë–¤ ì •ë³´ë¥¼ ì°¾ê³  ê³„ì‹ ê°€ìš”?\n",
      "ğŸ§  LLM ì‘ë‹µ: ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§  LLM ì‘ë‹µ: ì•„ì§ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì´ ì—†ìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì •ë³´ê°€ ìƒê¸°ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– ì•„ì§ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì´ ì—†ìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. í•„ìš”í•˜ì‹  ì •ë³´ê°€ ìƒê¸°ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§  LLM ì‘ë‹µ: í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "ğŸ§© Tool Calls: []\n",
      "ğŸ¤– í˜„ì¬ ì§ˆë¬¸ì´ ì—†ìœ¼ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_history = [\n",
    "    SystemMessage(\n",
    "    content=\"ë„ˆëŠ” ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´. ì‹¤ì‹œê°„ ì •ë³´ë‚˜ ëª¨ë¥´ëŠ” ê±´ ë°˜ë“œì‹œ tool_callì„ ìƒì„±í•´ì„œ ë„êµ¬ë¥¼ ì‚¬ìš©í•œ í›„, ë„êµ¬ ì‘ë‹µ(ToolMessage)ì„ ì°¸ê³ í•´ì„œ ë‹µë³€ì„ ë§Œë“¤ì–´ì•¼ í•´.\"\n",
    ")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"ğŸ‘¤ You: \")\n",
    "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    result = runnable.invoke({\"messages\": chat_history})\n",
    "    chat_history = result[\"messages\"]\n",
    "\n",
    "    print(\"ğŸ¤–\", chat_history[-1].content)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
