{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversation Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜',\n",
       " 'history': '',\n",
       " 'response': 'ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo')\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True, #verbose : ìƒì„¸ ë¡œê¹… ì—¬ë¶€\n",
    "    memory = ConversationBufferMemory(memory_key='history')\n",
    ")\n",
    "\n",
    "conversation.invoke({\"input\":\"ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "Human: ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜',\n",
       " 'history': 'Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\\nAI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.',\n",
       " 'response': 'ë¬¼ë¡ ì´ì£ ! ğŸ˜ŠğŸ¤–ğŸŒŒğŸ”¬ğŸ”­ğŸ“ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•´ ë“œë ¸ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ëª¨ì§€ë¥¼ ë” ì¶”ê°€í•´ ë“œë¦´ê¹Œìš”?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\":\"ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "Human: ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI: ë¬¼ë¡ ì´ì£ ! ğŸ˜ŠğŸ¤–ğŸŒŒğŸ”¬ğŸ”­ğŸ“ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•´ ë“œë ¸ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ëª¨ì§€ë¥¼ ë” ì¶”ê°€í•´ ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "Human: ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI: ë¬¼ë¡ ì´ì£ ! ğŸ˜ŠğŸ¤–ğŸŒŒğŸ”¬ğŸ”­ğŸ“ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•´ ë“œë ¸ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ëª¨ì§€ë¥¼ ë” ì¶”ê°€í•´ ë“œë¦´ê¹Œìš”?\n",
      "Human: ì•„ê¹Œ ëŒ€ë‹µí–ˆë˜ ë‹µë³€ì— ëŒ€í•´ì„œ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ì•„ê¹Œ ëŒ€ë‹µí–ˆë˜ ë‹µë³€ì— ëŒ€í•´ì„œ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜',\n",
       " 'history': 'Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\\nAI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\\nHuman: ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\\nAI: ë¬¼ë¡ ì´ì£ ! ğŸ˜ŠğŸ¤–ğŸŒŒğŸ”¬ğŸ”­ğŸ“ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•´ ë“œë ¸ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ëª¨ì§€ë¥¼ ë” ì¶”ê°€í•´ ë“œë¦´ê¹Œìš”?',\n",
       " 'response': 'ì–‘ìì—­í•™ì€ ğŸŒŒ ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ì„ ì—°êµ¬í•˜ëŠ” ë¬¼ë¦¬í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”. ğŸ˜ŠğŸ”¬ğŸ”­ğŸ“'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\" : \"ì•„ê¹Œ ëŒ€ë‹µí–ˆë˜ ë‹µë³€ì— ëŒ€í•´ì„œ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ê³¼ ìƒí˜¸ì‘ìš©ì„ ì—°êµ¬í•©ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ë¡ ì ì´ë©° íŒŒë™í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì–‘ìì—­í•™ì€ ë§¤ìš° ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ì§ê´€ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–‘ìì—­í•™ì€ ì›ì, ë¶„ì, ì›ìí•µ, ì…ìë¬¼ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "Human: ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI: ë¬¼ë¡ ì´ì£ ! ğŸ˜ŠğŸ¤–ğŸŒŒğŸ”¬ğŸ”­ğŸ“ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•´ ë“œë ¸ìŠµë‹ˆë‹¤. ì–´ë–¤ ì´ëª¨ì§€ë¥¼ ë” ì¶”ê°€í•´ ë“œë¦´ê¹Œìš”?\n",
      "Human: ì•„ê¹Œ ëŒ€ë‹µí–ˆë˜ ë‹µë³€ì— ëŒ€í•´ì„œ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ê³  ë” ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜\n",
      "AI: ì–‘ìì—­í•™ì€ ğŸŒŒ ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ì„ ì—°êµ¬í•˜ëŠ” ë¬¼ë¦¬í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œ ì •í™•í•˜ì§€ë§Œ ì´í•´í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”. ğŸ˜ŠğŸ”¬ğŸ”­ğŸ“\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**streaming : ì‹¤ì‹œê°„ ì¶œë ¥**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks.base import BaseCallbackHandler \n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token:str, **kwargs) -> None:\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "        \n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë°ì„ í™•ì„±í™”í•˜ê¸° ìœ„í•´ ChatModelì— streaming=True ì „ë‹¬\n",
    "stream_llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingHandler()]\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=stream_llm,\n",
    "    verbose=True,\n",
    "    memory = ConversationBufferMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI:\u001b[0m\n",
      " ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ì„ ì„¤ëª…í•˜ëŠ” ì´ë¡ ì…ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ì ì¸ ì„±ì§ˆì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì…ìë“¤ì´ íŒŒë™í•¨ìˆ˜ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ë¡ ì€ íŠ¹ì •í•œ ìƒí™©ì—ì„œ ì…ìì˜ ìœ„ì¹˜, ìš´ë™ëŸ‰ ë“±ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì–‘ìì—­í•™ì€ ë§¤ìš° í˜ì‹ ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì•¼ë¡œì„œ, ì–‘ì ì»´í“¨í„° ë° ì–‘ì í†µì‹ ê³¼ ê°™ì€ ê¸°ìˆ ì˜ ë°œì „ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input='ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: ì–‘ìì—­í•™ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\n",
      "AI:  ì–‘ìì—­í•™ì€ ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ë¡œì„œ, ì•„ì£¼ ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ì„ ì„¤ëª…í•˜ëŠ” ì´ë¡ ì…ë‹ˆë‹¤. ì–‘ìì—­í•™ì€ í™•ë¥ ì ì¸ ì„±ì§ˆì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì…ìë“¤ì´ íŒŒë™í•¨ìˆ˜ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ë¡ ì€ íŠ¹ì •í•œ ìƒí™©ì—ì„œ ì…ìì˜ ìœ„ì¹˜, ìš´ë™ëŸ‰ ë“±ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì–‘ìì—­í•™ì€ ë§¤ìš° í˜ì‹ ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì•¼ë¡œì„œ, ì–‘ì ì»´í“¨í„° ë° ì–‘ì í†µì‹ ê³¼ ê°™ì€ ê¸°ìˆ ì˜ ë°œì „ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "Human: ì´ì € ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½í•˜ê³  ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI: 1. ì–‘ìì—­í•™: ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ ì„¤ëª…\n",
      "2. í™•ë¥ ì  ì„±ì§ˆ, íŒŒë™í•¨ìˆ˜ ì´ìš©\n",
      "3. ìœ„ì¹˜, ìš´ë™ëŸ‰ ì˜ˆì¸¡ ê°€ëŠ¥\n",
      "4. í˜ì‹ ì  ê¸°ìˆ  ë°œì „ì— ì¤‘ìš” âš›ï¸ğŸ”®\n",
      "Human: ì´ì „ ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½í•˜ê³  ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜\n",
      "AI: AI: ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ ì´ì „ì— ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ ë‚´ìš©ì€ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "Human: í•œë²ˆ ë”í•´ì¤˜ ì™œ ì´ë ‡ê²Œ ë¶ˆì¹œì ˆí•´\n",
      "AI:\u001b[0m\n",
      "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ì „ì— ì´ë¯¸ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ìš”ì•½ëœ ë‚´ìš©ì„ ë‹¤ì‹œ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "1. ì–‘ìì—­í•™: ì‘ì€ ì…ìë“¤ì˜ í–‰ë™ ì„¤ëª…\n",
      "2. í™•ë¥ ì  ì„±ì§ˆ, íŒŒë™í•¨ìˆ˜ ì´ìš©\n",
      "3. ìœ„ì¹˜, ìš´ë™ëŸ‰ ì˜ˆì¸¡ ê°€ëŠ¥\n",
      "4. í˜ì‹ ì  ê¸°ìˆ  ë°œì „ì— ì¤‘ìš” âš›ï¸ğŸ”®\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(\n",
    "    input='í•œë²ˆ ë”í•´ì¤˜ ì™œ ì´ë ‡ê²Œ ë¶ˆì¹œì ˆí•´'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prompt íŠœë‹**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "#ëŒ€í™”ë‚´ìš©\n",
    "{chat_history}\n",
    "----\n",
    "ì‚¬ìš©ì : {question}\n",
    "ì—‘ì…€ì „ë¬¸ê°€:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.partial(chat_history=\"íŒŒì´ì¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationChain(memory=ConversationBufferMemory(memory_key='chat_history'), verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:'), llm=ChatOpenAI(callbacks=[<__main__.StreamingHandler object at 0x11f447010>], client=<openai.resources.chat.completions.Completions object at 0x11f74a020>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11f74b3d0>, openai_api_key=SecretStr('**********'), openai_proxy='', streaming=True), input_key='question')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConversationChain í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = stream_llm,\n",
    "    prompt = prompt,\n",
    "    verbose=True,\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history'), #ì–´ë–¤ ì •ë³´ë¥¼ ê¸°ì–µí•  ì§€ ê²°ì •\n",
    "    input_key='question' # ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” í‚¤\n",
    ")\n",
    "\n",
    "conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    ConversationChain(memory=ConversationBufferMemory(memory_key='chat_history'), verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='\\në‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{chat_history}\\n----\\nì‚¬ìš©ì : {question}\\nì—‘ì…€ì „ë¬¸ê°€:'), llm=ChatOpenAI(callbacks=[<__main__.StreamingHandler object at 0x11f447010>], client=<openai.resources.chat.completions.Completions object at 0x11f74a020>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11f74b3d0>, openai_api_key=SecretStr('**********'), openai_proxy='', streaming=True), input_key='question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "ë‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "#ëŒ€í™”ë‚´ìš©\n",
      "\n",
      "----\n",
      "ì‚¬ìš©ì : python ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë²• ì•Œë ¤ì£¼ì„¸ìš”\n",
      "ì—‘ì…€ì „ë¬¸ê°€:\u001b[0m\n",
      "ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ìœ¼ë¡œ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ì£¼ë¡œ pytestì´ë‚˜ unittestì™€ ê°™ì€ í…ŒìŠ¤íŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë˜í•œ mockì´ë‚˜ stubì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ì˜ì¡´ì„±ì„ ê°€ì§œ ê°ì²´ë¡œ ëŒ€ì²´í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì–¼ë§ˆë‚˜ ë§ì€ ì½”ë“œê°€ í…ŒìŠ¤íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ë“¤ì„ í†µí•´ íŒŒì´ì¬ ì½”ë“œì˜ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ìœ¼ë¡œ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ì£¼ë¡œ pytestì´ë‚˜ unittestì™€ ê°™ì€ í…ŒìŠ¤íŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë˜í•œ mockì´ë‚˜ stubì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ì˜ì¡´ì„±ì„ ê°€ì§œ ê°ì²´ë¡œ ëŒ€ì²´í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì–¼ë§ˆë‚˜ ë§ì€ ì½”ë“œê°€ í…ŒìŠ¤íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ë“¤ì„ í†µí•´ íŒŒì´ì¬ ì½”ë“œì˜ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = conversation.predict(\n",
    "    question = 'python ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë²• ì•Œë ¤ì£¼ì„¸ìš”'\n",
    ")\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "ë‹¹ì‹ ì€ 10ë…„ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "#ëŒ€í™”ë‚´ìš©\n",
      "Human: python ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë²• ì•Œë ¤ì£¼ì„¸ìš”\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ìœ¼ë¡œ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ í•˜ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ì£¼ë¡œ pytestì´ë‚˜ unittestì™€ ê°™ì€ í…ŒìŠ¤íŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ë˜í•œ mockì´ë‚˜ stubì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ì˜ì¡´ì„±ì„ ê°€ì§œ ê°ì²´ë¡œ ëŒ€ì²´í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë˜í•œ ì½”ë“œ ì»¤ë²„ë¦¬ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì–¼ë§ˆë‚˜ ë§ì€ ì½”ë“œê°€ í…ŒìŠ¤íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ë“¤ì„ í†µí•´ íŒŒì´ì¬ ì½”ë“œì˜ í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "----\n",
      "ì‚¬ìš©ì : ì˜ˆì œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "ì—‘ì…€ì „ë¬¸ê°€:\u001b[0m\n",
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "# calculator.py\n",
      "\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "```\n",
      "\n",
      "```python\n",
      "# test_calculator.py\n",
      "\n",
      "import pytest\n",
      "from calculator import add, subtract\n",
      "\n",
      "def test_add():\n",
      "    assert add(3, 4) == 7\n",
      "    assert add(-1, 1) == 0\n",
      "\n",
      "def test_subtract():\n",
      "    assert subtract(5, 2) == 3\n",
      "    assert subtract(10, 5) == 5\n",
      "```\n",
      "\n",
      "ì´ë ‡ê²Œ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³ , ê° í•¨ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ì—¬ pytestë¥¼ í†µí•´ ì‹¤í–‰í•˜ë©´ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.pytestëŠ” assertë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆìƒ ê²°ê³¼ì™€ ì‹¤ì œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³ , í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ°ì‹ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆê±°ë‚˜ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ë¬¼ë¡ ì…ë‹ˆë‹¤! ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\n\\nì˜ˆë¥¼ ë“¤ì–´, ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\\n\\n```python\\n# calculator.py\\n\\ndef add(x, y):\\n    return x + y\\n\\ndef subtract(x, y):\\n    return x - y\\n```\\n\\n```python\\n# test_calculator.py\\n\\nimport pytest\\nfrom calculator import add, subtract\\n\\ndef test_add():\\n    assert add(3, 4) == 7\\n    assert add(-1, 1) == 0\\n\\ndef test_subtract():\\n    assert subtract(5, 2) == 3\\n    assert subtract(10, 5) == 5\\n```\\n\\nì´ë ‡ê²Œ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³ , ê° í•¨ìˆ˜ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‘ì„±í•˜ì—¬ pytestë¥¼ í†µí•´ ì‹¤í–‰í•˜ë©´ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.pytestëŠ” assertë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆìƒ ê²°ê³¼ì™€ ì‹¤ì œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³ , í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.\\n\\nì´ëŸ°ì‹ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆê±°ë‚˜ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = conversation.predict(question=\"ì˜ˆì œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Human Prefix & AI Prefix ë³€ê²½**\n",
    "\n",
    "    - human ì ‘ë‘ì‚¬ë¥¼ ë³€ê²½í•œë‹¤.\n",
    "    - í•´ë‹¹ ì ‘ë‘ì‚¬ê°€ humanìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ë§Œ ì›í•˜ëŠ” ëŒ€ë¡œ ë³€ê²½ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
    "    í•´ë‹¹ ì ‘ë‘ì‚¬ë¥¼ ë³€ê²½í•˜ëŠ” ê²½ìš° ì²´ì¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ë„ ì´ë¦„ ë³€ê²½ì„ ë°˜ì˜í•˜ë„ë¡ ìˆ˜ì •í•´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='\\në‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{context}\\n\\n<ê³ ê°>: {question}\\n<ì „ë¬¸ê°€>:\\n')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "#ëŒ€í™”ë‚´ìš©\n",
    "{context}\n",
    "\n",
    "<ê³ ê°>: {question}\n",
    "<ì „ë¬¸ê°€>:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        PromptTemplate(input_variables=['context', 'question'], template='\\në‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{context}\\n\\n<ê³ ê°>: {question}\\n<ì „ë¬¸ê°€>:\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(human_prefix='<ê³ ê°>', ai_prefix='<ì „ë¬¸ê°€>', memory_key='context')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key='context',\n",
    "    human_prefix='<ê³ ê°>',\n",
    "    ai_prefix='<ì „ë¬¸ê°€>' \n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationChain(memory=ConversationBufferMemory(human_prefix='<ê³ ê°>', ai_prefix='<ì „ë¬¸ê°€>', memory_key='context'), verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template='\\në‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{context}\\n\\n<ê³ ê°>: {question}\\n<ì „ë¬¸ê°€>:\\n'), llm=ChatOpenAI(callbacks=[<__main__.StreamingHandler object at 0x11f447010>], client=<openai.resources.chat.completions.Completions object at 0x11f74a020>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11f74b3d0>, openai_api_key=SecretStr('**********'), openai_proxy='', streaming=True), input_key='question')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=stream_llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    input_key='question',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    ConversationChain(memory=ConversationBufferMemory(human_prefix='<ê³ ê°>', ai_prefix='<ì „ë¬¸ê°€>', memory_key='context'), verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template='\\në‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\\n\\n#ëŒ€í™”ë‚´ìš©\\n{context}\\n\\n<ê³ ê°>: {question}\\n<ì „ë¬¸ê°€>:\\n'), llm=ChatOpenAI(callbacks=[<__main__.StreamingHandler object at 0x11f447010>], client=<openai.resources.chat.completions.Completions object at 0x11f74a020>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11f74b3d0>, openai_api_key=SecretStr('**********'), openai_proxy='', streaming=True), input_key='question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "ë‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "#ëŒ€í™”ë‚´ìš©\n",
      "\n",
      "\n",
      "<ê³ ê°>: íŒŒì´ì¬ì—ì„œ ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²•ì€ ë­”ê°€ìš”? ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ˆì œ ì½”ë“œë¥¼ ë³´ë©´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "<ì „ë¬¸ê°€>:\n",
      "\u001b[0m\n",
      "ê°•ë„ í…ŒìŠ¤íŠ¸ëŠ” íŒŒì´ì¬ì—ì„œ ì£¼ë¡œ pytest ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ë©ë‹ˆë‹¤. pytestëŠ” íŒŒì´ì¬ì˜ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ë¡œ, ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ê°€ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "def test_add():\n",
      "    assert add(1, 2) == 3\n",
      "    assert add(0, 0) == 0\n",
      "    assert add(-1, 1) == 0\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œëŠ” add í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í•´ë‹¹ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” test_add í•¨ìˆ˜ë¥¼ ì‘ì„±í•œ ì˜ˆì œì…ë‹ˆë‹¤. ê°ê°ì˜ assert ë¬¸ì€ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¡°ê±´ì´ ë§ì§€ ì•Šì„ ê²½ìš° AssertionErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ ì‘ì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. pytestë¥¼ ì„¤ì¹˜í•œ í›„, í„°ë¯¸ë„ì—ì„œ í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ `pytest` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³ , ì½”ë“œì˜ ì‹ ë¢°ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = conversation.predict(\n",
    "    question = \"íŒŒì´ì¬ì—ì„œ ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²•ì€ ë­”ê°€ìš”? ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ˆì œ ì½”ë“œë¥¼ ë³´ë©´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "ë‹¹ì‹ ì€ 10ë……ì°¨ íŒŒì´ì¬ ë°±ì—”ë“œ ê°œë°œì ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³´ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "#ëŒ€í™”ë‚´ìš©\n",
      "<ê³ ê°>: íŒŒì´ì¬ì—ì„œ ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²•ì€ ë­”ê°€ìš”? ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ˆì œ ì½”ë“œë¥¼ ë³´ë©´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "<ì „ë¬¸ê°€>: ê°•ë„ í…ŒìŠ¤íŠ¸ëŠ” íŒŒì´ì¬ì—ì„œ ì£¼ë¡œ pytest ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ë©ë‹ˆë‹¤. pytestëŠ” íŒŒì´ì¬ì˜ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ë¡œ, ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ê°€ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "def test_add():\n",
      "    assert add(1, 2) == 3\n",
      "    assert add(0, 0) == 0\n",
      "    assert add(-1, 1) == 0\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œëŠ” add í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í•´ë‹¹ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” test_add í•¨ìˆ˜ë¥¼ ì‘ì„±í•œ ì˜ˆì œì…ë‹ˆë‹¤. ê°ê°ì˜ assert ë¬¸ì€ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¡°ê±´ì´ ë§ì§€ ì•Šì„ ê²½ìš° AssertionErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ ì‘ì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. pytestë¥¼ ì„¤ì¹˜í•œ í›„, í„°ë¯¸ë„ì—ì„œ í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ `pytest` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³ , ì½”ë“œì˜ ì‹ ë¢°ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "<ê³ ê°>: ë” ë³µì¡í•œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ê¸°ëŠ¥ì„ í™œìš©í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "<ì „ë¬¸ê°€>:\n",
      "\u001b[0m\n",
      "ë¬¼ë¡ ì…ë‹ˆë‹¤. ì¢€ ë” ë³µì¡í•œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "def calculate_total_price(prices, discounts):\n",
      "    total = sum(prices)\n",
      "    for discount in discounts:\n",
      "        total -= total * discount\n",
      "    return total\n",
      "\n",
      "def test_calculate_total_price():\n",
      "    prices = [100, 200, 300]\n",
      "    discounts = [0.1, 0.2]\n",
      "    \n",
      "    assert calculate_total_price(prices, discounts) == 360\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œëŠ” calculate_total_price í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í•´ë‹¹ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” test_calculate_total_price í•¨ìˆ˜ë¥¼ ì‘ì„±í•œ ì˜ˆì œì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ê°€ê²©(prices)ê³¼ í• ì¸ìœ¨(discounts)ì„ ë°›ì•„ ì´ ê°€ê²©ì„ ê³„ì‚°í•˜ëŠ” ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì½”ë“œì—ì„œëŠ” pricesì™€ discountsë¥¼ ì •ì˜í•˜ê³ , calculate_total_price í•¨ìˆ˜ë¥¼ í†µí•´ ê³„ì‚°ëœ ê²°ê³¼ê°€ ì˜ˆìƒí•œ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ ì‘ì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ë©´, í•´ë‹¹ í•¨ìˆ˜ì˜ ê¸°ëŠ¥ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.pytestë¥¼ í†µí•´ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì½”ë“œì˜ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ë§Œì•½ ì´ ì˜ˆì œì—ì„œ ì–´ë–¤ ê°’ì´ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë‚˜ì˜¨ë‹¤ë©´, í•´ë‹¹ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜¬ë°”ë¥¸ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = conversation.predict(question='ë” ë³µì¡í•œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ê¸°ëŠ¥ì„ í™œìš©í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ê³ ê°>: íŒŒì´ì¬ì—ì„œ ê°•ë„ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ë°©ë²•ì€ ë­”ê°€ìš”? ì‹¤ì œ ì„œë¹„ìŠ¤ ì˜ˆì œ ì½”ë“œë¥¼ ë³´ë©´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "<ì „ë¬¸ê°€>: ê°•ë„ í…ŒìŠ¤íŠ¸ëŠ” íŒŒì´ì¬ì—ì„œ ì£¼ë¡œ pytest ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰ë©ë‹ˆë‹¤. pytestëŠ” íŒŒì´ì¬ì˜ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ì¤‘ í•˜ë‚˜ë¡œ, ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ê°€ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "def test_add():\n",
      "    assert add(1, 2) == 3\n",
      "    assert add(0, 0) == 0\n",
      "    assert add(-1, 1) == 0\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œëŠ” add í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í•´ë‹¹ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” test_add í•¨ìˆ˜ë¥¼ ì‘ì„±í•œ ì˜ˆì œì…ë‹ˆë‹¤. ê°ê°ì˜ assert ë¬¸ì€ íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¡°ê±´ì´ ë§ì§€ ì•Šì„ ê²½ìš° AssertionErrorë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ ì‘ì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œëŠ” pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. pytestë¥¼ ì„¤ì¹˜í•œ í›„, í„°ë¯¸ë„ì—ì„œ í•´ë‹¹ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ `pytest` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³ , ì½”ë“œì˜ ì‹ ë¢°ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "<ê³ ê°>: ë” ë³µì¡í•œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ ê¸°ëŠ¥ì„ í™œìš©í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”\n",
      "<ì „ë¬¸ê°€>: ë¬¼ë¡ ì…ë‹ˆë‹¤. ì¢€ ë” ë³µì¡í•œ ì„œë¹„ìŠ¤ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì˜ˆì œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "def calculate_total_price(prices, discounts):\n",
      "    total = sum(prices)\n",
      "    for discount in discounts:\n",
      "        total -= total * discount\n",
      "    return total\n",
      "\n",
      "def test_calculate_total_price():\n",
      "    prices = [100, 200, 300]\n",
      "    discounts = [0.1, 0.2]\n",
      "    \n",
      "    assert calculate_total_price(prices, discounts) == 360\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œëŠ” calculate_total_price í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , í•´ë‹¹ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” test_calculate_total_price í•¨ìˆ˜ë¥¼ ì‘ì„±í•œ ì˜ˆì œì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ê°€ê²©(prices)ê³¼ í• ì¸ìœ¨(discounts)ì„ ë°›ì•„ ì´ ê°€ê²©ì„ ê³„ì‚°í•˜ëŠ” ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì½”ë“œì—ì„œëŠ” pricesì™€ discountsë¥¼ ì •ì˜í•˜ê³ , calculate_total_price í•¨ìˆ˜ë¥¼ í†µí•´ ê³„ì‚°ëœ ê²°ê³¼ê°€ ì˜ˆìƒí•œ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ ì‘ì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ pytestë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•˜ë©´, í•´ë‹¹ í•¨ìˆ˜ì˜ ê¸°ëŠ¥ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.pytestë¥¼ í†µí•´ ê°•ë„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì½”ë“œì˜ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ë§Œì•½ ì´ ì˜ˆì œì—ì„œ ì–´ë–¤ ê°’ì´ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë‚˜ì˜¨ë‹¤ë©´, í•´ë‹¹ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜¬ë°”ë¥¸ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    memory.load_memory_variables({})['context']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
