{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048,\n",
    "    model_name='gpt-3.5-turbo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Python Poetry는 Python 프로젝트의 의존성 관리 및 패키지 배포를 위한 도구입니다. Poetry를 사용하면 프로젝트의 의존성을 관리하는 데 필요한 작업을 자동화하고, 가상 환경을 관리하며, 패키지를 빌드하고 배포하는 과정을 간편하게 수행할 수 있습니다.\\n\\nPoetry는 pyproject.toml 파일을 사용하여 프로젝트의 의존성 및 설정을 정의하고, Poetry의 명령어를 사용하여 의존성을 설치하고 업데이트할 수 있습니다. 또한 Poetry를 사용하면 패키지를 빌드하고 PyPI에 배포하는 과정을 자동화할 수 있습니다.\\n\\nPython Poetry를 사용하면 프로젝트의 의존성을 관리하는 데 필요한 번거로운 작업을 간편하게 처리할 수 있으며, 프로젝트의 환경을 깔끔하게 유지할 수 있습니다. 따라서 Python 개발자들 사이에서 널리 사용되고 있는 도구입니다.' response_metadata={'token_usage': {'completion_tokens': 321, 'prompt_tokens': 17, 'total_tokens': 338}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "question = 'python poetry에 대해 설명해줘'\n",
    "result = llm.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    content='Python Poetry는 Python 프로젝트의 의존성 관리 및 패키지 배포를 위한 도구입니다. Poetry를 사용하면 프로젝트의 의존성을 관리하는 데 필요한 작업을 자동화하고, 가상 환경을 관리하며, 패키지를 빌드하고 배포하는 과정을 간편하게 수행할 수 있습니다.\\n\\nPoetry는 pyproject.toml 파일을 사용하여 프로젝트의 의존성 및 설정을 정의하고, Poetry의 명령어를 사용하여 의존성을 설치하고 업데이트할 수 있습니다. 또한 Poetry를 사용하면 패키지를 빌드하고 PyPI에 배포하는 과정을 자동화할 수 있습니다.\\n\\nPython Poetry를 사용하면 프로젝트의 의존성을 관리하는 데 필요한 번거로운 작업을 간편하게 처리할 수 있으며, 프로젝트의 환경을 깔끔하게 유지할 수 있습니다. 따라서 Python 개발자들 사이에서 널리 사용되고 있는 도구입니다.' response_metadata={'token_usage': {'completion_tokens': 321, 'prompt_tokens': 17, 'total_tokens': 338}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prompt template**\n",
    "\n",
    "        - user input을 이용해 prompt 만드는 template\n",
    "        - template : template 문자열, `{}`는 변수\n",
    "        - input_variables : 중괄호에 들어갈 변수의 이름. 리스트로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"{country}의 수도는 뭐야?\"\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLMChian**\n",
    "\n",
    "    - LLMChain : PromptTemplate과 연결된 체인 객체 생성\n",
    "    - prompt : PromptTemplate 객체 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1196de9e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x119c50100>, temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=2048))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt = prompt, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': '대한민국', 'text': '대한민국의 수도는 서울이야.'}\n",
      "{'country': '네덜란드', 'text': '네덜란드의 수도는 암스테르담입니다.'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.invoke(({'country':'대한민국'})))\n",
    "print(llm_chain.invoke(({'country':'네덜란드'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '호주의 수도는 캔버라입니다.'},\n",
       " {'text': '중국의 수도는 베이징(北京)입니다.'},\n",
       " {'text': '베트남의 수도는 하노이(Hanoi)입니다.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply\n",
    "\n",
    "input_list = [{'country':'호주'}, {'country':'중국'}, {'country':'베트남'}]\n",
    "response = llm_chain.apply(input_list)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '호주의 수도는 캔버라입니다.'}\n",
      "{'text': '중국의 수도는 베이징(北京)입니다.'}\n",
      "{'text': '베트남의 수도는 하노이(Hanoi)입니다.'}\n"
     ]
    }
   ],
   "source": [
    "print(response[0])\n",
    "print(response[1])\n",
    "print(response[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호주의 수도는 캔버라입니다.\n",
      "중국의 수도는 베이징(北京)입니다.\n",
      "베트남의 수도는 하노이(Hanoi)입니다.\n"
     ]
    }
   ],
   "source": [
    "for res in response:\n",
    "    print(res['text'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 19, 'total_tokens': 37}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))], [ChatGeneration(text='베트남의 수도는 하노이(Hanoi)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='베트남의 수도는 하노이(Hanoi)입니다.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 20, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))]] llm_output={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 56, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c'} run=[RunInfo(run_id=UUID('85fa51b8-d1a9-4fed-8014-54c122e8deb7')), RunInfo(run_id=UUID('6b189caa-ddc5-40b9-af66-e6080442c9e9')), RunInfo(run_id=UUID('45db0643-a80d-4ff7-82b9-44f03029125c'))]\n"
     ]
    }
   ],
   "source": [
    "## generate() : 문자열 데신에 LLMResult를 반환함 / 토큰 사용량과 종료 이유 같은 생성 정보를 포함함\n",
    "\n",
    "\n",
    "input_list = [{'country':'호주'}, {'country':'중국'}, {'country':'베트남'}]\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LLMResult(generations=[[ChatGeneration(\n",
    "            text='호주의 수도는 캔버라입니다.', \n",
    "            generation_info={'finish_reason': 'stop', 'logprobs': None},\n",
    "            message=AIMessage(\n",
    "                content='호주의 수도는 캔버라입니다.', \n",
    "                response_metadata={\n",
    "                    'token_usage': {\n",
    "                        'completion_tokens': 13, \n",
    "                        'prompt_tokens': 17, \n",
    "                        'total_tokens': 30\n",
    "                        },\n",
    "                    'model_name': \n",
    "                        'gpt-3.5-turbo',\n",
    "                        'system_fingerprint': 'fp_3bc1b5746c',\n",
    "                        'finish_reason': 'stop', \n",
    "                        'logprobs': None\n",
    "                        }\n",
    "                )\n",
    "            )\n",
    "                                ],\n",
    "                            [ChatGeneration(\n",
    "                                text='중국의 수도는 베이징(北京)입니다.',\n",
    "                                generation_info={'finish_reason': 'stop', 'logprobs': None},\n",
    "                                message=AIMessage(\n",
    "                                    content='중국의 수도는 베이징(北京)입니다.',\n",
    "                                    response_metadata={\n",
    "                                        'token_usage': {\n",
    "                                            'completion_tokens': 18,\n",
    "                                            'prompt_tokens': 19,\n",
    "                                            'total_tokens': 37\n",
    "                                            }, \n",
    "                                        'model_name': 'gpt-3.5-turbo',\n",
    "                                            'system_fingerprint':'fp_3bc1b5746c', \n",
    "                                            'finish_reason': 'stop', \n",
    "                                            'logprobs': None\n",
    "                                                    }\n",
    "                                    )\n",
    "                                )\n",
    "                                ], [ChatGeneration(\n",
    "                                    text='베트남의 수도는 하노이(Hanoi)입니다.',\n",
    "                                    generation_info={\n",
    "                                        'finish_reason':  'stop',\n",
    "                                        'logprobs': None\n",
    "                                            }, \n",
    "                                    message=AIMessage(\n",
    "                                        content='베트남의 수도는 하노이(Hanoi)입니다.', \n",
    "                                        response_metadata={\n",
    "                                            'token_usage': {\n",
    "                                                'completion_tokens': 18,\n",
    "                                                'prompt_tokens': 20, \n",
    "                                                'total_tokens': 38\n",
    "                                                }, \n",
    "                                            'model_name': 'gpt-3.5-turbo', \n",
    "                                            'system_fingerprint': 'fp_3bc1b5746c', \n",
    "                                            'finish_reason': 'stop', \n",
    "                                            'logprobs': None\n",
    "                                            }\n",
    "                                        )\n",
    "                                    )\n",
    "                                    ]\n",
    "                                ]\n",
    "                , llm_output={\n",
    "                    'token_usage': {\n",
    "                        'completion_tokens': 49, \n",
    "                        'prompt_tokens': 56, \n",
    "                        'total_tokens': 105\n",
    "                        },\n",
    "                    'model_name': 'gpt-3.5-turbo', \n",
    "                    'system_fingerprint': 'fp_3bc1b5746c'\n",
    "                    }, \n",
    "                run=[RunInfo(\n",
    "                    run_id=UUID(\n",
    "                        '85fa51b8-d1a9-4fed-8014-54c122e8deb7'\n",
    "                        )\n",
    "                    ), \n",
    "                    RunInfo(\n",
    "                        run_id=UUID(\n",
    "                            '6b189caa-ddc5-40b9-af66-e6080442c9e9'\n",
    "                            )\n",
    "                        ), \n",
    "                    RunInfo(\n",
    "                        run_id=UUID(\n",
    "                            '45db0643-a80d-4ff7-82b9-44f03029125c'\n",
    "                            )\n",
    "                        )\n",
    "                    \n",
    "                    ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 49,\n",
       "  'prompt_tokens': 56,\n",
       "  'total_tokens': 105},\n",
       " 'model_name': 'gpt-3.5-turbo',\n",
       " 'system_fingerprint': 'fp_3bc1b5746c'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token 사용량\n",
    "generated_result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))],\n",
       " [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 19, 'total_tokens': 37}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))],\n",
       " [ChatGeneration(text='베트남의 수도는 하노이(Hanoi)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='베트남의 수도는 하노이(Hanoi)입니다.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 20, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'호주의 수도는 캔버라입니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason': 'stop', 'logprobs': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0][0].generation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0][0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'호주의 수도는 캔버라입니다.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_result.generations[0][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**두 개 이상의 변수를 template 안에 정의** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['area1', 'area2'], template='{area1} 과 {area2}의 시차는 몇 시간이야?')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{area1} 과 {area2}의 시차는 몇 시간이야?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['area1', 'area2'], template='{area1} 과 {area2}의 시차는 몇 시간이야?'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1196de9e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x119c50100>, temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=2048))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LLMChain(\n",
    "        prompt=PromptTemplate(\n",
    "            input_variables=[\n",
    "                'area1', 'area2'\n",
    "                ], \n",
    "            template='{area1} 과 {area2}의 시차는 몇 시간이야?'\n",
    "            ), \n",
    "        llm=ChatOpenAI(\n",
    "            client=<openai.resources.chat.completions.Completions object at 0x1196de9e0>, \n",
    "            async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x119c50100>,\n",
    "            temperature=0.1, \n",
    "            openai_api_key=SecretStr('**********'),\n",
    "            openai_proxy='', \n",
    "            max_tokens=2048\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area1': '서울',\n",
       " 'area2': '네덜란드',\n",
       " 'text': '서울과 네덜란드의 시차는 8시간입니다. 서울은 GMT+9 시간대에 속하고, 네덜란드는 GMT+1 시간대에 속하기 때문에 시차는 8시간입니다.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_chain.invoke({'area1' : '서울', 'area2' : '네덜란드'})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '서울과 영국의 시차는 9시간입니다. 서울은 GMT+9 시간대에 속하고, 영국은 GMT+0 시간대에 속해 있기 때문입니다.'}, {'text': '서울과 치앙마이의 시차는 2시간입니다. 서울은 GMT+9 시간대에 속해 있고, 치앙마이는 GMT+7 시간대에 속해 있기 때문입니다.'}, {'text': '서울과 네덜란드의 시차는 8시간입니다. 서울은 UTC+9 시간대에 위치하고, 네덜란드는 UTC+1 시간대에 위치하기 때문입니다.'}]\n"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'area1' : '서울', 'area2' :'영국'},\n",
    "    {'area1' : '서울', 'area2' :'치앙마이'},\n",
    "    {'area1' : '서울', 'area2' :'네덜란드'},\n",
    "]\n",
    "\n",
    "result = llm_chain.apply(input_list)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울과 영국의 시차는 9시간입니다. 서울은 GMT+9 시간대에 속하고, 영국은 GMT+0 시간대에 속해 있기 때문입니다.\n",
      "서울과 치앙마이의 시차는 2시간입니다. 서울은 GMT+9 시간대에 속해 있고, 치앙마이는 GMT+7 시간대에 속해 있기 때문입니다.\n",
      "서울과 네덜란드의 시차는 8시간입니다. 서울은 UTC+9 시간대에 위치하고, 네덜란드는 UTC+1 시간대에 위치하기 때문입니다.\n"
     ]
    }
   ],
   "source": [
    "for res in result:\n",
    "    print(res['text'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**steam : 실시간 출력**\n",
    "     \n",
    "     - 질의에 대한 답변을 실시간으로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name = 'gpt-3.5-turbo',\n",
    "    max_tokens=2048,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python으로 서비스를 출시하기 위해 꼭 알아야 하는 라이브러리는 다양하겠지만, 주요한 몇 가지 라이브러리를 소개해 드리겠습니다.\n",
      "\n",
      "1. Flask 또는 Django: 웹 애플리케이션을 개발하기 위한 프레임워크로, Flask는 가벼우면서도 유연한 웹 프레임워크이며, Django는 기능이 풍부하고 확장성이 뛰어난 웹 프레임워크입니다.\n",
      "\n",
      "2. SQLAlchemy: 데이터베이스와의 상호작용을 쉽게 만들어주는 ORM(Object-Relational Mapping) 라이브러리로, 데이터베이스와의 연동을 간편하게 처리할 수 있습니다.\n",
      "\n",
      "3. requests: HTTP 요청을 보내고 받는 데 사용되는 라이브러리로, 외부 API와의 통신이나 웹 크롤링 등에 유용하게 활용됩니다.\n",
      "\n",
      "4. Celery: 비동기 작업을 처리하기 위한 분산 작업 큐 라이브러리로, 백그라운드 작업이나 스케줄링된 작업을 효율적으로 처리할 수 있습니다.\n",
      "\n",
      "5. Flask-RESTful 또는 Django REST framework: RESTful API를 개발하기 위한 라이브러리로, API 서버를 구축하고 관리하는 데 유용하게 활용됩니다.\n",
      "\n",
      "이 외에도 필요에 따라 다양한 라이브러리를 추가로 사용할 수 있으며, Python의 생태계는 매우 다양하고 활발하므로 필요한 기능에 맞는 라이브러리를 선택하여 활용하면 됩니다."
     ]
    }
   ],
   "source": [
    "question = 'python으로 서비스를 출시하기 위해 꼭 알아야하는 라이브러리에 대해 상세히 알려줘'\n",
    "\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
