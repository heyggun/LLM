{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## langsmith에서 디버깅을 위해 사용하는 코드\n",
    "import os \n",
    "\n",
    "LANGCHAIN_TRACING_V2=True\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_PROJECT=\"LCEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num'], template='{num}의 10배는?')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{num}의 10배는?\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num'], template='{num}의 10배는?')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1474fea10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1475c7fd0>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = prompt | ChatOpenAI(model='gpt-3.5-turbo')\n",
    "chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='50', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 15, 'total_tokens': 16}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"num\":5})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터를 효과적으로 전달하는 방법**\n",
    "\n",
    "    - RunnablePassthrough는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있다.\n",
    "    주로 RunnableParallel과 함께 사용되어 맵에서 새 키에 데이터를 할당하는데 사용한다.\n",
    "    - RunnablePassthrough()이 단독으로 호출되면 단순히 입력을 받아 그대로 전달한다.\n",
    "    assign(RunnablePassthrough.assgin(..)) 과 함께 호출되면 입력을 받아 assign 함수에 전달된 추가 인수를 추가한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='20입니다.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 15, 'total_tokens': 18}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough\n",
    "\n",
    "chain.invoke({\"num\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuunablePassthrough 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='100', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 15, 'total_tokens': 16}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnablePassthrough.assgin() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"num\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"]*3)).invoke({\"num\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RunnableParallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'multi': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# RunnableParallel 인스턴스 생성. 여러 Runnable 인스턴스를 병렬로 실행\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    # RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달. 입력된 데이터를 그대로 통과시킴\n",
    "    passed = RunnablePassthrough(),\n",
    "    # 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용해 'mult' lambda function 할당. 해당 함수는 num 키에 해당하는 값을 3배로 증가시킴\n",
    "    extra = RunnablePassthrough().assign(multi = lambda x: x[\"num\"]*3),\n",
    "    # 'modified' 키워드 인자로 lambda function 전달, 이 함수는 입력된 딕셔너리의 num키에 해당하는 값에 1을 더함\n",
    "    modified = lambda x: x[\"num\"] +1\n",
    ") \n",
    "\n",
    "# runnable 인스턴스에 {'num':1} 딕셔너리를 입력으로 전달해 invoke 메소드를 호출\n",
    "\n",
    "runnable.invoke({\"num\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain도 RunnableParallel\n",
    "\n",
    "chain1 = (\n",
    "    {\"num\" : RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{num}의 10배는? \\답변(결과만) : \")\n",
    "    | ChatOpenAI(model='gpt-3.5-turbo')\n",
    ")\n",
    "\n",
    "chain2 = (\n",
    "    {\"num\" : RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{num} 의 1/10배는? \\답변:(결과만) : \")\n",
    "    | ChatOpenAI(model='gpt-3.5-turbo')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': AIMessage(content='100', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 32, 'total_tokens': 33}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}),\n",
       " 'b': AIMessage(content='1', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 35, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = RunnableParallel(a=chain1, b=chain2)\n",
    "combined_chain.invoke({\"num\":10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RunnableLambda**\n",
    "\n",
    "    - RunnableLambda로 사용자 정의 함수 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra(x):\n",
    "    ext = x['extra']\n",
    "    return int(ext[\"num\"] * int(ext[\"multi\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(runnable | RunnableLambda(extra)).invoke({\"num\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
