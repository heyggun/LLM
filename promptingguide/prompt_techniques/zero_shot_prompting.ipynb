{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87857393-6369-4b66-87c9-5f3253edf28e",
   "metadata": {},
   "source": [
    "# Prompt Engineering : Zero-shot-prompting\n",
    "\n",
    "오늘날 GPT-3 같은 LLM은 지침(instruction)을 따르도록 조정되고, 많은 양의 데이터로 학습됐기 때문에 일부 작업은 ‘zero-shot’ 으로 수행할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac673e1",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66de8ca6",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b0686-bea6-41a2-b879-88721dc0ec10",
   "metadata": {},
   "source": [
    "## Zero_shot_prompting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05d8a20-86f2-4613-835e-41c49a504b5b",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "prompt= \"\"\"\n",
    "        Classify the text into neutral, negative or positive. \n",
    "        Text: I think the vacation is okay.\n",
    "        Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20fc56",
   "metadata": {
    "height": 30
   },
   "source": [
    "    위 프롬프트에서 모델에게 분류와 함께 텍스트 예제를 제공하지 않았지만, LLM은 이미 \"감정\"을 이해하고 있다.\n",
    "    해당 프롬포트 기술은 “zero-shot prompting” 이다.\n",
    "\n",
    "    Wei et al. ( 2022) 에 따르면 Instruction tuning은 zero-shot 학습을 향상시킨다.\n",
    "    Instruction tuning은 본질적으로 지침(Instruction)을 통해 설명되는 데이터 세트에 대한 미세 조정 모델이다.\n",
    "\n",
    "    또한 RLHF(인간 피드백을 통한 강화학습)은 모델이 인간 선호도에 더 잘 맞게 조정되는 instruction tuning을 확장하기 위해 채택됐다.\n",
    "    이 최근 개발은 ChatGPT와 같은 모델에 영향을 미쳤다. \n",
    "\n",
    "    zero-shot이 작동하지 않을 때는 프롬프트에서 시연이나 예제를 제공하여 few-shot prompt를 생성하는 것이 좋다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
